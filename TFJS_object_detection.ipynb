{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFJS object detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZSL793i7KuM"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7HMItRf7oCR"
      },
      "source": [
        "#### **Setup Training Configuration**\r\n",
        "Configure all the necessary parameters for training.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVPzEKoLuEHy"
      },
      "source": [
        "NUM_TRAIN_STEPS = 500\n",
        "MODEL_TYPE = 'ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18'\n",
        "CONFIG_TYPE = 'ssd_mobilenet_v1_quantized_300x300_coco14_sync'\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "CHECKPOINT_PATH = '/content/checkpoint'\n",
        "OUTPUT_PATH     = '/content/output'\n",
        "EXPORTED_PATH   = '/content/exported'\n",
        "DATA_PATH       = '/content/data'\n",
        "\n",
        "LABEL_MAP_PATH    = os.path.join(DATA_PATH, 'labelmap.pbtxt')\n",
        "TRAIN_RECORD_PATH = os.path.join(DATA_PATH, 'train.record')\n",
        "VAL_RECORD_PATH   = os.path.join(DATA_PATH, 'val.record')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRio1HrL8Nv_"
      },
      "source": [
        "#### **Mount Google Drive**\r\n",
        "To access the dataset stored on your Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqulgiPXPIjX",
        "outputId": "51ca49bc-0c92-41fd-ce66-ced5bafa25a6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XINCKkPshgz"
      },
      "source": [
        "#### **Install the TensorFlow Object Detection API**\n",
        "Install and setup TensorFlow Object Detection API, Protobuf and other necessary dependencies.\n",
        "\n",
        "\n",
        "### Dependencies\n",
        "Most of the dependencies required come preloaded in Google Colab. The only additional package we need to install is TensorFlow.js, which is used for converting our trained model to a model that is compatible for the web.\n",
        "\n",
        "### Protocol Buffers\n",
        "The TensorFlow Object Detection API relies on what are called `protocol buffers` (also known as `protobufs`). Protobufs are a language neutral way to describe information. That means you can write a protobuf once and then compile it to be used with other languages, like Python, Java or C.\n",
        "\n",
        "The `protoc` command used below is compiling all the protocol buffers in the `object_detection/protos` folder for Python.\n",
        "\n",
        "### Environment\n",
        "To use the object detection api we need to add it to our `PYTHONPATH` along with `slim` which contains code for training and evaluating several widely used Convolutional Neural Network (CNN) image classification models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o33_jgwGm3NV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13e5fd0-c138-41d4-adc2-b474063fe028"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/cloud-annotations/models\n",
        "\n",
        "!pip install cloud-annotations==0.0.4\n",
        "!pip install tf_slim\n",
        "!pip install lvis\n",
        "!pip install --no-deps tensorflowjs==1.4.0\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "pwd = os.getcwd()\n",
        "os.environ['PYTHONPATH'] += f':{pwd}:{pwd}/slim'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 2282, done.\u001b[K\n",
            "remote: Counting objects: 100% (2282/2282), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1930/1930), done.\u001b[K\n",
            "remote: Total 2282 (delta 523), reused 1238 (delta 326), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2282/2282), 30.58 MiB | 37.02 MiB/s, done.\n",
            "Resolving deltas: 100% (523/523), done.\n",
            "Collecting cloud-annotations==0.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/33/db/7bd769f9b1ed088088d30883fe79cbb3a0f300942a088e1467ff6b5792d5/cloud_annotations-0.0.4-py3-none-any.whl\n",
            "Installing collected packages: cloud-annotations\n",
            "Successfully installed cloud-annotations-0.0.4\n",
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 15.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n",
            "Collecting lvis\n",
            "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.19.5)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.6/dist-packages (from lvis) (0.29.21)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (0.10.0)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (2.4.7)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (2.8.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from lvis) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.6/dist-packages (from lvis) (3.2.2)\n",
            "Installing collected packages: lvis\n",
            "Successfully installed lvis-0.5.3\n",
            "Collecting tensorflowjs==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/73/f7ee6edced75b7dfe43916203f1b2e85dd14cba087a090e6372cbd82e462/tensorflowjs-1.4.0-py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.4MB/s \n",
            "\u001b[?25hInstalling collected packages: tensorflowjs\n",
            "Successfully installed tensorflowjs-1.4.0\n",
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS1ZDbJ660Wv"
      },
      "source": [
        "#### **Test the setup**\n",
        "Run the model builder test to verify if everything is setup successfully."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM8sOHwL64Rp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c3122a1-fcda-489e-806b-d9485731a463"
      },
      "source": [
        "!python object_detection/builders/model_builder_tf1_test.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running tests under Python 3.6.9: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params0 (True)\n",
            "[       OK ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params0 (True)\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params1 (False)\n",
            "[       OK ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params1 (False)\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_experimental_model\n",
            "[       OK ] ModelBuilderTF1Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_rfcn_model_from_config\n",
            "[       OK ] ModelBuilderTF1Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_ssd_fpn_model_from_config\n",
            "[       OK ] ModelBuilderTF1Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_ssd_models_from_config\n",
            "[       OK ] ModelBuilderTF1Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF1Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[       OK ] ModelBuilderTF1Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF1Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[       OK ] ModelBuilderTF1Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF1Test.test_invalid_model_config_proto\n",
            "[       OK ] ModelBuilderTF1Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF1Test.test_invalid_second_stage_batch_size\n",
            "[       OK ] ModelBuilderTF1Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF1Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF1Test.test_session\n",
            "[ RUN      ] ModelBuilderTF1Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[       OK ] ModelBuilderTF1Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF1Test.test_unknown_meta_architecture\n",
            "[       OK ] ModelBuilderTF1Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF1Test.test_unknown_ssd_feature_extractor\n",
            "[       OK ] ModelBuilderTF1Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 21 tests in 0.140s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atqPXVFsGi0p"
      },
      "source": [
        "#### **Copy the dataset folder from Google Drive.**\r\n",
        "Get the dataset of images and annotations saved on your Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNd9QWcSGmRJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb69a22-fa24-486c-e5eb-7d6937fb316e"
      },
      "source": [
        "%cp -r /content/drive/MyDrive/TFJS-Custom-Detection/ /content/\r\n",
        "%cd /content/\r\n",
        "%mkdir data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/TFJS-Custom-Detection/xml_to_csv.py': No such file or directory\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZb1b-rjM7PI"
      },
      "source": [
        "#### **Load the xml_to_csv.py**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGNNM7MNSCRQ",
        "outputId": "882e1035-04c7-47d1-ec37-391bbd663b91"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34mmodels\u001b[0m/  \u001b[01;34msample_data\u001b[0m/  \u001b[01;34mTFJS-Custom-Detection\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGUCc5O6M6WC",
        "outputId": "bd977186-2167-4a49-a708-afe3ac9f763e"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/NSTiwari/TensorFlow.js-Custom-Object-Detection/master/xml_to_csv.py -P /content/TFJS-Custom-Detection/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-09 10:24:01--  https://raw.githubusercontent.com/NSTiwari/TensorFlow.js-Custom-Object-Detection/master/xml_to_csv.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1223 (1.2K) [text/plain]\n",
            "Saving to: ‘/content/TFJS-Custom-Detection/xml_to_csv.py.1’\n",
            "\n",
            "\rxml_to_csv.py.1       0%[                    ]       0  --.-KB/s               \rxml_to_csv.py.1     100%[===================>]   1.19K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-02-09 10:24:01 (69.1 MB/s) - ‘/content/TFJS-Custom-Detection/xml_to_csv.py.1’ saved [1223/1223]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIeVJuP-H7js"
      },
      "source": [
        "#### **Convert XML annotations into CSV**\r\n",
        "All the PascalVOC labels are converted into a CSV file for training and testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxLqiPs1ICBd",
        "outputId": "b2c41c0f-c5df-460c-ffc7-c43ac1016b00"
      },
      "source": [
        "%cd /content/\r\n",
        "!python TFJS-Custom-Detection/xml_to_csv.py"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Successfully converted xml to csv.\n",
            "Successfully converted xml to csv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXaNy-s69rY1"
      },
      "source": [
        "#### **Create labelmap.pbtxt file inside the data folder** \r\n",
        "Consider the following example:\r\n",
        "```\r\n",
        "item {\r\n",
        "  name: \"cat\"\r\n",
        "  id: 1\r\n",
        "}\r\n",
        " \r\n",
        "item {\r\n",
        "  name: \"dog\"\r\n",
        "  id: 2\r\n",
        "}\r\n",
        " \r\n",
        "item {\r\n",
        "  name: \"fish\"\r\n",
        "  id: 3\r\n",
        "}\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQKAUNPoKuJE"
      },
      "source": [
        "#### **Create TFRecord**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDNHPYho-jpo"
      },
      "source": [
        "Download the generate_tf_record.py file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M_gZYnuU2Ng",
        "outputId": "8522b1bb-a537-4686-f9a0-e02dd07f3f56"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/NSTiwari/TensorFlow.js-Custom-Object-Detection/master/generate_tf_records.py -P /content/"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-09 10:26:32--  https://raw.githubusercontent.com/NSTiwari/TensorFlow.js-Custom-Object-Detection/master/generate_tf_records.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5136 (5.0K) [text/plain]\n",
            "Saving to: ‘/content/generate_tf_records.py’\n",
            "\n",
            "\rgenerate_tf_records   0%[                    ]       0  --.-KB/s               \rgenerate_tf_records 100%[===================>]   5.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-02-09 10:26:32 (80.1 MB/s) - ‘/content/generate_tf_records.py’ saved [5136/5136]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDNPhElwLm-x",
        "outputId": "4481e872-4b50-4683-c7fe-9a221de21d7b"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/   generate_tf_records.py  \u001b[01;34msample_data\u001b[0m/\n",
            "\u001b[01;34mdrive\u001b[0m/  \u001b[01;34mmodels\u001b[0m/                 \u001b[01;34mTFJS-Custom-Detection\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ontcE6e_K5ji",
        "outputId": "b2331506-0e9d-4890-af24-bd73029bc60b"
      },
      "source": [
        "!python generate_tf_records.py -l /content/data/labelmap.pbtxt -o data/train.record -i TFJS-Custom-Detection/images -csv TFJS-Custom-Detection/train_labels.csv\r\n",
        "!python generate_tf_records.py -l /content/data/labelmap.pbtxt -o data/val.record -i TFJS-Custom-Detection/images -csv TFJS-Custom-Detection/val_labels.csv"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:Successfully created the TFRecords: data/train.record\n",
            "INFO:Successfully created the TFRecords: data/val.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmuIKk5H-dfY"
      },
      "source": [
        "#### **Navigate to models/research directory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjisT1-wE6T8",
        "outputId": "621b3a03-9908-419b-c02b-462801a4df9e"
      },
      "source": [
        "%cd /content/models/research"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6DhYpAS7gX2"
      },
      "source": [
        "#### **Download a base model**\n",
        "Training a model from scratch can take a lot of computation time. Instead, we choose to apply Transfer Learning on a pre-trained model. Transfer Learning helps to decrease computations and time, of course, to a great extent. The base model we'll be using is the MobileNet model which is very fast."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHD1Jm0v7jfz"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "\n",
        "import six.moves.urllib as urllib\n",
        "\n",
        "download_base = 'http://download.tensorflow.org/models/object_detection/'\n",
        "model = MODEL_TYPE + '.tar.gz'\n",
        "tmp = '/content/checkpoint.tar.gz'\n",
        "\n",
        "if not (os.path.exists(CHECKPOINT_PATH)):\n",
        "  # Download the checkpoint\n",
        "  opener = urllib.request.URLopener()\n",
        "  opener.retrieve(download_base + model, tmp)\n",
        "\n",
        "  # Extract all the `model.ckpt` files.\n",
        "  with tarfile.open(tmp) as tar:\n",
        "    for member in tar.getmembers():\n",
        "      member.name = os.path.basename(member.name)\n",
        "      if 'model.ckpt' in member.name:\n",
        "        tar.extract(member, path=CHECKPOINT_PATH)\n",
        "\n",
        "  os.remove(tmp)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXlvFvwUHrui"
      },
      "source": [
        "#### **Model Configuration**\n",
        "Before the training begins, we need to configure the training pipeline by specifying the paths for labelmap, TFRecord and checkpoint. The default batch size is 128 which also needs to be changed as it is too large to be handled by Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfg2vAr7DzBV",
        "outputId": "2258c1c1-5e3c-4db2-9cb6-4ce2d75fd86f"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34ma3c_blogpost\u001b[0m/        \u001b[01;34mdeep_speech\u001b[0m/            \u001b[01;34mpcl_rl\u001b[0m/\n",
            "\u001b[01;34madversarial_text\u001b[0m/    \u001b[01;34mdelf\u001b[0m/                   README.md\n",
            "\u001b[01;34mattention_ocr\u001b[0m/       \u001b[01;34mefficient-hrl\u001b[0m/          \u001b[01;34mrebar\u001b[0m/\n",
            "\u001b[01;34maudioset\u001b[0m/            \u001b[01;34mlfads\u001b[0m/                  \u001b[01;34msequence_projection\u001b[0m/\n",
            "\u001b[01;34mautoaugment\u001b[0m/         \u001b[01;34mlstm_object_detection\u001b[0m/  setup.py\n",
            "\u001b[01;34mcognitive_planning\u001b[0m/  \u001b[01;34mmarco\u001b[0m/                  \u001b[01;34mslim\u001b[0m/\n",
            "\u001b[01;34mcvt_text\u001b[0m/            \u001b[01;34mnst_blogpost\u001b[0m/           \u001b[01;34mvid2depth\u001b[0m/\n",
            "\u001b[01;34mdeeplab\u001b[0m/             \u001b[01;34mobject_detection\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8CVExv6HsJS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a085e40c-8a28-43f3-ef9f-2fa4ab50811e"
      },
      "source": [
        "import re\n",
        "\n",
        "from google.protobuf import text_format\n",
        "\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "pipeline_skeleton = '/content/models/research/object_detection/samples/configs/' + CONFIG_TYPE + '.config'\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_skeleton)\n",
        "\n",
        "label_map = label_map_util.get_label_map_dict(LABEL_MAP_PATH)\n",
        "num_classes = len(label_map.keys())\n",
        "meta_arch = configs[\"model\"].WhichOneof(\"model\")\n",
        "\n",
        "override_dict = {\n",
        "  'model.{}.num_classes'.format(meta_arch): num_classes,\n",
        "  'train_config.batch_size': 24,\n",
        "  'train_input_path': TRAIN_RECORD_PATH,\n",
        "  'eval_input_path': VAL_RECORD_PATH,\n",
        "  'train_config.fine_tune_checkpoint': os.path.join(CHECKPOINT_PATH, 'model.ckpt'),\n",
        "  'label_map_path': LABEL_MAP_PATH\n",
        "}\n",
        "\n",
        "configs = config_util.merge_external_params_with_configs(configs, kwargs_dict=override_dict)\n",
        "pipeline_config = config_util.create_pipeline_proto_from_configs(configs)\n",
        "config_util.save_pipeline_config(pipeline_config, DATA_PATH)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Maybe overwriting model.ssd.num_classes: 5\n",
            "INFO:tensorflow:Maybe overwriting train_config.batch_size: 24\n",
            "INFO:tensorflow:Maybe overwriting train_input_path: /content/data/train.record\n",
            "INFO:tensorflow:Maybe overwriting eval_input_path: /content/data/val.record\n",
            "INFO:tensorflow:Maybe overwriting train_config.fine_tune_checkpoint: /content/checkpoint/model.ckpt\n",
            "INFO:tensorflow:Maybe overwriting label_map_path: /content/data/labelmap.pbtxt\n",
            "INFO:tensorflow:Writing pipeline config file to /content/data/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNYIZK1xVNAa"
      },
      "source": [
        "#### **Start training**\n",
        "Run the cell below to start training the model. Training is invoked by calling the `model_main` script and passing the following arguments to it.\n",
        "\n",
        "- The location of the `pipepline.config` we created\n",
        "- Where we want to save the model\n",
        "- How many steps we want to train the model (the longer you train, the more potential there is to learn)\n",
        "- The number of evaluation steps (or how often to test the model) gives us an idea of how well the model is doing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv5h2bwBVO0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bfb1459-44f7-4907-ff4e-f090b4874a6d"
      },
      "source": [
        "!rm -rf $OUTPUT_PATH\n",
        "!python -m object_detection.model_main \\\n",
        "    --pipeline_config_path=$DATA_PATH/pipeline.config \\\n",
        "    --model_dir=$OUTPUT_PATH \\\n",
        "    --num_train_steps=$NUM_TRAIN_STEPS \\\n",
        "    --num_eval_steps=100"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0209 10:27:35.103387 140488675989376 model_lib.py:801] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 500\n",
            "I0209 10:27:35.103610 140488675989376 config_util.py:552] Maybe overwriting train_steps: 500\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0209 10:27:35.103724 140488675989376 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0209 10:27:35.103813 140488675989376 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0209 10:27:35.103898 140488675989376 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0209 10:27:35.104007 140488675989376 model_lib.py:817] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I0209 10:27:35.104112 140488675989376 model_lib.py:852] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc592383b00>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0209 10:27:35.104547 140488675989376 estimator.py:212] Using config: {'_model_dir': '/content/output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc592383b00>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fc59238c6a8>) includes params argument, but params are not passed to Estimator.\n",
            "W0209 10:27:35.104771 140488675989376 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fc59238c6a8>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0209 10:27:35.105629 140488675989376 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0209 10:27:35.105834 140488675989376 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0209 10:27:35.106060 140488675989376 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0209 10:27:35.110756 140488675989376 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/data/train.record']\n",
            "I0209 10:27:35.139914 140488675989376 dataset_builder.py:148] Reading unweighted datasets: ['/content/data/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/data/train.record']\n",
            "I0209 10:27:35.140695 140488675989376 dataset_builder.py:77] Reading record datasets for input file: ['/content/data/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0209 10:27:35.140816 140488675989376 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0209 10:27:35.140900 140488675989376 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0209 10:27:35.145858 140488675989376 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0209 10:27:35.165893 140488675989376 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc5923e7588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0209 10:27:35.204844 140488675989376 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc5923e7588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7fc5befcef28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0209 10:27:35.383744 140488675989376 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7fc5befcef28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:92: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0209 10:27:35.384948 140488675989376 deprecation.py:323] From /content/models/research/object_detection/inputs.py:92: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0209 10:27:35.397738 140488675989376 deprecation.py:323] From /content/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0209 10:27:35.506249 140488675989376 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:264: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0209 10:27:36.290914 140488675989376 deprecation.py:323] From /content/models/research/object_detection/inputs.py:264: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0209 10:27:36.731238 140488675989376 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0209 10:27:36.742726 140488675989376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:27:38.360415 140488675989376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:27:38.390028 140488675989376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:27:38.418777 140488675989376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:27:38.447806 140488675989376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:27:38.478996 140488675989376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:27:38.508246 140488675989376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n",
            "I0209 10:27:46.109386 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n",
            "I0209 10:27:46.109850 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n",
            "I0209 10:27:46.110177 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n",
            "I0209 10:27:46.110537 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n",
            "I0209 10:27:46.110891 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n",
            "I0209 10:27:46.111293 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n",
            "I0209 10:27:46.111706 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n",
            "I0209 10:27:46.112083 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n",
            "I0209 10:27:46.112421 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n",
            "I0209 10:27:46.112804 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n",
            "I0209 10:27:46.113165 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n",
            "I0209 10:27:46.113484 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n",
            "I0209 10:27:46.113784 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n",
            "I0209 10:27:46.114084 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n",
            "I0209 10:27:46.114371 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n",
            "I0209 10:27:46.114686 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n",
            "I0209 10:27:46.114986 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n",
            "I0209 10:27:46.115295 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n",
            "I0209 10:27:46.115612 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n",
            "I0209 10:27:46.115931 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n",
            "I0209 10:27:46.116219 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n",
            "I0209 10:27:46.116531 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n",
            "I0209 10:27:46.116828 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n",
            "I0209 10:27:46.117132 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n",
            "I0209 10:27:46.117424 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n",
            "I0209 10:27:46.117748 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n",
            "I0209 10:27:46.118042 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0209 10:27:51.381870 140488675989376 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0209 10:27:51.383049 140488675989376 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0209 10:27:54.266813 140488675989376 monitored_session.py:240] Graph was finalized.\n",
            "2021-02-09 10:27:54.278548: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-02-09 10:27:54.278802: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1729df80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-02-09 10:27:54.278836: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-02-09 10:27:54.283303: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-02-09 10:27:54.481013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:27:54.481702: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1729ddc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-02-09 10:27:54.481732: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-02-09 10:27:54.483138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:27:54.483733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-02-09 10:27:54.484055: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-02-09 10:27:54.711909: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-02-09 10:27:54.831087: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-02-09 10:27:54.875602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-02-09 10:27:55.124924: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-02-09 10:27:55.175464: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-02-09 10:27:55.649911: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-09 10:27:55.650116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:27:55.650802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:27:55.651314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-02-09 10:27:55.655038: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-02-09 10:27:55.656402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-02-09 10:27:55.656431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-02-09 10:27:55.656459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-02-09 10:27:55.670358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:27:55.671248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:27:55.672051: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-02-09 10:27:55.672104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0209 10:28:05.357009 140488675989376 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0209 10:28:05.675120 140488675989376 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /content/output/model.ckpt.\n",
            "I0209 10:28:14.285704 140488675989376 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /content/output/model.ckpt.\n",
            "2021-02-09 10:28:28.482471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-02-09 10:28:31.440785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "INFO:tensorflow:loss = 4.0692134, step = 0\n",
            "I0209 10:28:39.452671 140488675989376 basic_session_run_hooks.py:262] loss = 4.0692134, step = 0\n",
            "INFO:tensorflow:global_step/sec: 1.31522\n",
            "I0209 10:29:55.484531 140488675989376 basic_session_run_hooks.py:692] global_step/sec: 1.31522\n",
            "INFO:tensorflow:loss = 1.3134124, step = 100 (76.033 sec)\n",
            "I0209 10:29:55.485528 140488675989376 basic_session_run_hooks.py:260] loss = 1.3134124, step = 100 (76.033 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.52114\n",
            "I0209 10:31:01.224654 140488675989376 basic_session_run_hooks.py:692] global_step/sec: 1.52114\n",
            "INFO:tensorflow:loss = 1.1600633, step = 200 (65.740 sec)\n",
            "I0209 10:31:01.225607 140488675989376 basic_session_run_hooks.py:260] loss = 1.1600633, step = 200 (65.740 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50586\n",
            "I0209 10:32:07.631645 140488675989376 basic_session_run_hooks.py:692] global_step/sec: 1.50586\n",
            "INFO:tensorflow:loss = 0.8556697, step = 300 (66.407 sec)\n",
            "I0209 10:32:07.632818 140488675989376 basic_session_run_hooks.py:260] loss = 0.8556697, step = 300 (66.407 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.49575\n",
            "I0209 10:33:14.487943 140488675989376 basic_session_run_hooks.py:692] global_step/sec: 1.49575\n",
            "INFO:tensorflow:loss = 0.92305225, step = 400 (66.856 sec)\n",
            "I0209 10:33:14.489226 140488675989376 basic_session_run_hooks.py:260] loss = 0.92305225, step = 400 (66.856 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 500 into /content/output/model.ckpt.\n",
            "I0209 10:34:20.590658 140488675989376 basic_session_run_hooks.py:606] Saving checkpoints for 500 into /content/output/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/data/val.record']\n",
            "I0209 10:34:21.920836 140488675989376 dataset_builder.py:148] Reading unweighted datasets: ['/content/data/val.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/data/val.record']\n",
            "I0209 10:34:21.921617 140488675989376 dataset_builder.py:77] Reading record datasets for input file: ['/content/data/val.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0209 10:34:21.921758 140488675989376 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc58017c1d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0209 10:34:21.963489 140488675989376 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc58017c1d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fc58ae278c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0209 10:34:22.125565 140488675989376 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fc58ae278c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0209 10:34:22.640912 140488675989376 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:34:23.986741 140488675989376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:34:24.016930 140488675989376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:34:24.046287 140488675989376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:34:24.075389 140488675989376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:34:24.103790 140488675989376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:34:24.132651 140488675989376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n",
            "I0209 10:34:25.884796 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n",
            "I0209 10:34:25.885123 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n",
            "I0209 10:34:25.885322 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n",
            "I0209 10:34:25.885527 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n",
            "I0209 10:34:25.885716 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n",
            "I0209 10:34:25.885907 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n",
            "I0209 10:34:25.886091 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n",
            "I0209 10:34:25.886281 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n",
            "I0209 10:34:25.886472 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n",
            "I0209 10:34:25.886659 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n",
            "I0209 10:34:25.886838 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n",
            "I0209 10:34:25.887031 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n",
            "I0209 10:34:25.887212 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n",
            "I0209 10:34:25.887397 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n",
            "I0209 10:34:25.887589 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n",
            "I0209 10:34:25.887790 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n",
            "I0209 10:34:25.887972 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n",
            "I0209 10:34:25.888215 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n",
            "I0209 10:34:25.888411 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n",
            "I0209 10:34:25.888620 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n",
            "I0209 10:34:25.888820 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n",
            "I0209 10:34:25.889032 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n",
            "I0209 10:34:25.889233 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n",
            "I0209 10:34:25.889428 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n",
            "I0209 10:34:25.889630 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n",
            "I0209 10:34:25.889815 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n",
            "I0209 10:34:25.889996 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\n",
            "I0209 10:34:25.890174 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I0209 10:34:25.890354 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\n",
            "I0209 10:34:25.890539 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I0209 10:34:25.890718 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\n",
            "I0209 10:34:25.890894 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I0209 10:34:25.891074 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\n",
            "I0209 10:34:25.891251 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I0209 10:34:25.891428 140488675989376 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:927: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0209 10:34:25.916008 140488675989376 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:927: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0209 10:34:26.118867 140488675989376 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0209 10:34:26.676997 140488675989376 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-02-09T10:34:26Z\n",
            "I0209 10:34:26.691931 140488675989376 evaluation.py:255] Starting evaluation at 2021-02-09T10:34:26Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0209 10:34:27.159108 140488675989376 monitored_session.py:240] Graph was finalized.\n",
            "2021-02-09 10:34:27.160272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:34:27.160639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-02-09 10:34:27.160779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-02-09 10:34:27.160823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-02-09 10:34:27.160859: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-02-09 10:34:27.160885: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-02-09 10:34:27.160912: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-02-09 10:34:27.160941: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-02-09 10:34:27.160979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-09 10:34:27.161077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:34:27.161397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:34:27.161658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-02-09 10:34:27.161744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-02-09 10:34:27.161761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-02-09 10:34:27.161775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-02-09 10:34:27.161881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:34:27.162195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:34:27.162469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from /content/output/model.ckpt-500\n",
            "I0209 10:34:27.163648 140488675989376 saver.py:1284] Restoring parameters from /content/output/model.ckpt-500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0209 10:34:28.185384 140488675989376 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0209 10:34:28.321244 140488675989376 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 7 images.\n",
            "I0209 10:34:31.396972 140484760725248 coco_evaluation.py:282] Performing evaluation on 7 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0209 10:34:31.397486 140484760725248 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0209 10:34:31.398035 140484760725248 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.04s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.556\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.923\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.615\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.556\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.540\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.620\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.620\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.620\n",
            "INFO:tensorflow:Finished evaluation at 2021-02-09-10:34:32\n",
            "I0209 10:34:32.056843 140488675989376 evaluation.py:275] Finished evaluation at 2021-02-09-10:34:32\n",
            "INFO:tensorflow:Saving dict for global step 500: DetectionBoxes_Precision/mAP = 0.5559296, DetectionBoxes_Precision/mAP (large) = 0.5559296, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9229923, DetectionBoxes_Precision/mAP@.75IOU = 0.6151815, DetectionBoxes_Recall/AR@1 = 0.54, DetectionBoxes_Recall/AR@10 = 0.62, DetectionBoxes_Recall/AR@100 = 0.62, DetectionBoxes_Recall/AR@100 (large) = 0.62, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.38544306, Loss/localization_loss = 0.19688065, Loss/regularization_loss = 0.28106725, Loss/total_loss = 0.8633909, global_step = 500, learning_rate = 0.095, loss = 0.8633909\n",
            "I0209 10:34:32.057129 140488675989376 estimator.py:2049] Saving dict for global step 500: DetectionBoxes_Precision/mAP = 0.5559296, DetectionBoxes_Precision/mAP (large) = 0.5559296, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9229923, DetectionBoxes_Precision/mAP@.75IOU = 0.6151815, DetectionBoxes_Recall/AR@1 = 0.54, DetectionBoxes_Recall/AR@10 = 0.62, DetectionBoxes_Recall/AR@100 = 0.62, DetectionBoxes_Recall/AR@100 (large) = 0.62, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.38544306, Loss/localization_loss = 0.19688065, Loss/regularization_loss = 0.28106725, Loss/total_loss = 0.8633909, global_step = 500, learning_rate = 0.095, loss = 0.8633909\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: /content/output/model.ckpt-500\n",
            "I0209 10:34:32.827228 140488675989376 estimator.py:2109] Saving 'checkpoint_path' summary for global step 500: /content/output/model.ckpt-500\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I0209 10:34:32.828031 140488675989376 exporter.py:410] Performing the final export in the end of training.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0209 10:34:33.102464 140488675989376 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:34:34.456935 140488675989376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:34:34.484739 140488675989376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:34:34.514990 140488675989376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:34:34.543756 140488675989376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:34:34.570776 140488675989376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:34:34.597656 140488675989376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0209 10:34:35.275590 140488675989376 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0209 10:34:35.275892 140488675989376 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I0209 10:34:35.276558 140488675989376 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I0209 10:34:35.276684 140488675989376 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I0209 10:34:35.276771 140488675989376 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I0209 10:34:35.276846 140488675989376 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I0209 10:34:35.276924 140488675989376 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2021-02-09 10:34:35.277530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:34:35.277859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-02-09 10:34:35.277969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-02-09 10:34:35.278000: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-02-09 10:34:35.278032: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-02-09 10:34:35.278058: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-02-09 10:34:35.278085: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-02-09 10:34:35.278113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-02-09 10:34:35.278143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-09 10:34:35.278237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:34:35.278588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:34:35.278846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-02-09 10:34:35.278895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-02-09 10:34:35.278912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-02-09 10:34:35.278926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-02-09 10:34:35.279030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:34:35.279338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:34:35.279616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from /content/output/model.ckpt-500\n",
            "I0209 10:34:35.281862 140488675989376 saver.py:1284] Restoring parameters from /content/output/model.ckpt-500\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I0209 10:34:35.583659 140488675989376 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0209 10:34:35.583873 140488675989376 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/output/export/Servo/temp-b'1612866872'/saved_model.pb\n",
            "I0209 10:34:36.107811 140488675989376 builder_impl.py:425] SavedModel written to: /content/output/export/Servo/temp-b'1612866872'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 0.7693649.\n",
            "I0209 10:34:36.440393 140488675989376 estimator.py:371] Loss for final step: 0.7693649.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwNtvgtdoB-C"
      },
      "source": [
        "#### **Export inference graph**\n",
        "Checkpoints are generated after every 500 training steps. Each checkpoint is a snapshot of your model at that point in training. If for some reason the training crashes due to network or power failure, then you can continue the training from the last checkpoint instead of starting it all over.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZgP_FZUoE0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81c162b9-b92f-4706-e6ee-f9fb9fe2ea46"
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "regex = re.compile(r\"model\\.ckpt-([0-9]+)\\.index\")\n",
        "numbers = [int(regex.search(f).group(1)) for f in os.listdir(OUTPUT_PATH) if regex.search(f)]\n",
        "TRAINED_CHECKPOINT_PREFIX = os.path.join(OUTPUT_PATH, 'model.ckpt-{}'.format(max(numbers)))\n",
        "\n",
        "print(f'Using {TRAINED_CHECKPOINT_PREFIX}')\n",
        "\n",
        "!rm -rf $EXPORTED_PATH\n",
        "!python -m object_detection.export_inference_graph \\\n",
        "  --pipeline_config_path=$DATA_PATH/pipeline.config \\\n",
        "  --trained_checkpoint_prefix=$TRAINED_CHECKPOINT_PREFIX \\\n",
        "  --output_directory=$EXPORTED_PATH"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using /content/output/model.ckpt-500\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0209 10:40:12.292329 140145918982016 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:40:13.607385 140145918982016 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:40:13.644659 140145918982016 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:40:13.680136 140145918982016 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:40:13.716378 140145918982016 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:40:13.751749 140145918982016 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0209 10:40:13.786987 140145918982016 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:595: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0209 10:40:14.025313 140145918982016 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:595: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0209 10:40:14.455078 140145918982016 deprecation.py:323] From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n",
            "I0209 10:40:15.417989 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n",
            "I0209 10:40:15.418318 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n",
            "I0209 10:40:15.418531 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n",
            "I0209 10:40:15.418733 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n",
            "I0209 10:40:15.418918 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n",
            "I0209 10:40:15.419106 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n",
            "I0209 10:40:15.419290 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n",
            "I0209 10:40:15.419491 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n",
            "I0209 10:40:15.419683 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n",
            "I0209 10:40:15.419872 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n",
            "I0209 10:40:15.420054 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n",
            "I0209 10:40:15.420241 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n",
            "I0209 10:40:15.420419 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n",
            "I0209 10:40:15.420622 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n",
            "I0209 10:40:15.420804 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n",
            "I0209 10:40:15.420989 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n",
            "I0209 10:40:15.421167 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n",
            "I0209 10:40:15.421352 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n",
            "I0209 10:40:15.421546 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n",
            "I0209 10:40:15.421743 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n",
            "I0209 10:40:15.421920 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n",
            "I0209 10:40:15.422105 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n",
            "I0209 10:40:15.422283 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n",
            "I0209 10:40:15.422478 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n",
            "I0209 10:40:15.422666 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n",
            "I0209 10:40:15.422852 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n",
            "I0209 10:40:15.423029 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\n",
            "I0209 10:40:15.423207 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I0209 10:40:15.423394 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\n",
            "I0209 10:40:15.423596 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I0209 10:40:15.423779 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\n",
            "I0209 10:40:15.423958 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I0209 10:40:15.424134 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\n",
            "I0209 10:40:15.424311 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I0209 10:40:15.424498 140145918982016 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0209 10:40:15.426099 140145918982016 deprecation.py:323] From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0209 10:40:15.426564 140145918982016 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "186 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/5.55m params)\n",
            "  BoxPredictor_0 (--/15.39k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor (--/6.16k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n",
            "    BoxPredictor_0/ClassPredictor (--/9.23k params)\n",
            "      BoxPredictor_0/ClassPredictor/biases (18, 18/18 params)\n",
            "      BoxPredictor_0/ClassPredictor/weights (1x1x512x18, 9.22k/9.22k params)\n",
            "  BoxPredictor_1 (--/61.50k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor (--/24.60k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1024x24, 24.58k/24.58k params)\n",
            "    BoxPredictor_1/ClassPredictor (--/36.90k params)\n",
            "      BoxPredictor_1/ClassPredictor/biases (36, 36/36 params)\n",
            "      BoxPredictor_1/ClassPredictor/weights (1x1x1024x36, 36.86k/36.86k params)\n",
            "  BoxPredictor_2 (--/30.78k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "    BoxPredictor_2/ClassPredictor (--/18.47k params)\n",
            "      BoxPredictor_2/ClassPredictor/biases (36, 36/36 params)\n",
            "      BoxPredictor_2/ClassPredictor/weights (1x1x512x36, 18.43k/18.43k params)\n",
            "  BoxPredictor_3 (--/15.42k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_3/ClassPredictor (--/9.25k params)\n",
            "      BoxPredictor_3/ClassPredictor/biases (36, 36/36 params)\n",
            "      BoxPredictor_3/ClassPredictor/weights (1x1x256x36, 9.22k/9.22k params)\n",
            "  BoxPredictor_4 (--/15.42k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_4/ClassPredictor (--/9.25k params)\n",
            "      BoxPredictor_4/ClassPredictor/biases (36, 36/36 params)\n",
            "      BoxPredictor_4/ClassPredictor/weights (1x1x256x36, 9.22k/9.22k params)\n",
            "  BoxPredictor_5 (--/7.74k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "    BoxPredictor_5/ClassPredictor (--/4.64k params)\n",
            "      BoxPredictor_5/ClassPredictor/biases (36, 36/36 params)\n",
            "      BoxPredictor_5/ClassPredictor/weights (1x1x128x36, 4.61k/4.61k params)\n",
            "  FeatureExtractor (--/5.41m params)\n",
            "    FeatureExtractor/MobilenetV1 (--/5.41m params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_0 (--/864 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_0/weights (3x3x3x32, 864/864 params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_10_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_10_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_11_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_11_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_12_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_12_pointwise (--/524.29k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights (1x1x512x1024, 524.29k/524.29k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_depthwise (--/9.22k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights (3x3x1024x1, 9.22k/9.22k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise (--/1.05m params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights (1x1x1024x1024, 1.05m/1.05m params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256 (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_1_depthwise (--/288 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_1_pointwise (--/2.05k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights (1x1x32x64, 2.05k/2.05k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_2_depthwise (--/576 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_2_pointwise (--/8.19k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights (1x1x64x128, 8.19k/8.19k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_3_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_3_pointwise (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights (1x1x128x128, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_4_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_4_pointwise (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights (1x1x128x256, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_5_depthwise (--/2.30k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_5_pointwise (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights (1x1x256x256, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_6_depthwise (--/2.30k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_6_pointwise (--/131.07k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights (1x1x256x512, 131.07k/131.07k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_7_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_7_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_8_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_8_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_9_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_9_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "186 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/5.42m flops)\n",
            "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/mul_fold (1.18m/1.18m flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/mul_fold (1.05m/1.05m flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/mul_fold (524.29k/524.29k flops)\n",
            "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n",
            "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n",
            "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/mul_fold (262.14k/262.14k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/mul_fold (262.14k/262.14k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/mul_fold (262.14k/262.14k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/mul_fold (262.14k/262.14k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/mul_fold (262.14k/262.14k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/mul_fold (262.14k/262.14k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/mul_fold (131.07k/131.07k flops)\n",
            "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/mul_fold (73.73k/73.73k flops)\n",
            "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/mul_fold (65.54k/65.54k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/mul_fold (65.54k/65.54k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/mul_fold (32.77k/32.77k flops)\n",
            "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/mul_fold (32.77k/32.77k flops)\n",
            "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/mul_fold (16.38k/16.38k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/mul_fold (16.38k/16.38k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/mul_fold (9.22k/9.22k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/mul_fold (8.19k/8.19k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/mul_fold (4.61k/4.61k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/mul_fold (4.61k/4.61k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/mul_fold (4.61k/4.61k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/mul_fold (4.61k/4.61k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/mul_fold (4.61k/4.61k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/mul_fold (4.61k/4.61k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/mul_fold (2.30k/2.30k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/mul_fold (2.30k/2.30k flops)\n",
            "  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/mul_fold (2.05k/2.05k flops)\n",
            "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/mul_fold (1.15k/1.15k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/mul_fold (1.15k/1.15k flops)\n",
            "  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/mul_fold (864/864 flops)\n",
            "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/mul_fold (576/576 flops)\n",
            "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/mul_fold (288/288 flops)\n",
            "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
            "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
            "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
            "  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
            "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "2021-02-09 10:40:17.385454: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-02-09 10:40:17.428568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:17.429134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-02-09 10:40:17.429420: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-02-09 10:40:17.430986: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-02-09 10:40:17.432596: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-02-09 10:40:17.432945: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-02-09 10:40:17.442823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-02-09 10:40:17.453005: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-02-09 10:40:17.466731: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-09 10:40:17.466882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:17.467648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:17.468151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-02-09 10:40:17.473177: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-02-09 10:40:17.473366: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x18dad80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-02-09 10:40:17.473394: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-02-09 10:40:17.582022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:17.582722: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x18daf40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-02-09 10:40:17.582759: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-02-09 10:40:17.582959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:17.583545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-02-09 10:40:17.583632: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-02-09 10:40:17.583662: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-02-09 10:40:17.583691: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-02-09 10:40:17.583717: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-02-09 10:40:17.583741: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-02-09 10:40:17.583768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-02-09 10:40:17.583795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-09 10:40:17.583888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:17.584481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:17.584994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-02-09 10:40:17.585075: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-02-09 10:40:17.586225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-02-09 10:40:17.586263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-02-09 10:40:17.586277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-02-09 10:40:17.586414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:17.586985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:17.587515: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-02-09 10:40:17.587560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from /content/output/model.ckpt-500\n",
            "I0209 10:40:17.589349 140145918982016 saver.py:1284] Restoring parameters from /content/output/model.ckpt-500\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0209 10:40:19.206444 140145918982016 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2021-02-09 10:40:19.706246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:19.706892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-02-09 10:40:19.706986: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-02-09 10:40:19.707012: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-02-09 10:40:19.707039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-02-09 10:40:19.707062: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-02-09 10:40:19.707087: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-02-09 10:40:19.707111: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-02-09 10:40:19.707135: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-09 10:40:19.707222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:19.707785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:19.708287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-02-09 10:40:19.708331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-02-09 10:40:19.708346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-02-09 10:40:19.708355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-02-09 10:40:19.708454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:19.709017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:19.709522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from /content/output/model.ckpt-500\n",
            "I0209 10:40:19.710627 140145918982016 saver.py:1284] Restoring parameters from /content/output/model.ckpt-500\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0209 10:40:20.350857 140145918982016 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0209 10:40:20.351130 140145918982016 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 387 variables.\n",
            "I0209 10:40:20.719704 140145918982016 graph_util_impl.py:334] Froze 387 variables.\n",
            "INFO:tensorflow:Converted 387 variables to const ops.\n",
            "I0209 10:40:20.799151 140145918982016 graph_util_impl.py:394] Converted 387 variables to const ops.\n",
            "2021-02-09 10:40:20.930721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:20.931295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-02-09 10:40:20.931381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-02-09 10:40:20.931406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-02-09 10:40:20.931428: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-02-09 10:40:20.931466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-02-09 10:40:20.931509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-02-09 10:40:20.931530: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-02-09 10:40:20.931551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-09 10:40:20.931641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:20.932187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:20.932683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-02-09 10:40:20.932723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-02-09 10:40:20.932738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-02-09 10:40:20.932747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-02-09 10:40:20.932841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:20.933371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-09 10:40:20.933875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0209 10:40:21.456579 140145918982016 deprecation.py:323] From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0209 10:40:21.457242 140145918982016 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0209 10:40:21.457380 140145918982016 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/exported/saved_model/saved_model.pb\n",
            "I0209 10:40:21.710637 140145918982016 builder_impl.py:425] SavedModel written to: /content/exported/saved_model/saved_model.pb\n",
            "INFO:tensorflow:Writing pipeline config file to /content/exported/pipeline.config\n",
            "I0209 10:40:21.733485 140145918982016 config_util.py:254] Writing pipeline config file to /content/exported/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfIiNcb0OWk6"
      },
      "source": [
        "#### **Testing the model**\n",
        "Now, let's test the model on some images. Remember that the model was trained only for 500 steps. So, the accuracy might not be that great. Run the cell below to test the model for yourself and find out how well the model was trained.\n",
        "\n",
        "> **Note:** Try training the model for 5,000 steps and see how the accuracy changes. Play around with other model formats, like the non-quantized version of SSD MobileNet v1 or Faster R-CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWHvlnyjmCIN"
      },
      "source": [
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import tensorflow as tf\n",
        "\n",
        "# Use javascipt to take a photo.\n",
        "def take_photo(filename, quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename\n",
        "\n",
        "try:\n",
        "  take_photo('/content/photo.jpg')\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))\n",
        "\n",
        "# Use the captured photo to make predictions\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image as PImage\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "# Load the labels\n",
        "category_index = label_map_util.create_category_index_from_labelmap(LABEL_MAP_PATH, use_display_name=True)\n",
        "\n",
        "# Load the model\n",
        "path_to_frozen_graph = os.path.join(EXPORTED_PATH, 'frozen_inference_graph.pb')\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(path_to_frozen_graph, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "with detection_graph.as_default():\n",
        "  with tf.Session(graph=detection_graph) as sess:\n",
        "    # Definite input and output Tensors for detection_graph\n",
        "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "    # Each box represents a part of the image where a particular object was detected.\n",
        "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "    # Each score represent how level of confidence for each of the objects.\n",
        "    # Score is shown on the result image, together with the class label.\n",
        "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "    image = PImage.open('/content/photo.jpg')\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    (im_width, im_height) = image.size\n",
        "    image_np = np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    (boxes, scores, classes, num) = sess.run(\n",
        "        [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "        feed_dict={image_tensor: image_np_expanded})\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        np.squeeze(boxes),\n",
        "        np.squeeze(classes).astype(np.int32),\n",
        "        np.squeeze(scores),\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(image_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVmCc9NPkP3U"
      },
      "source": [
        "#### **Convert the model into TFJS**\n",
        "The model we exported works well with Python. However, to deploy it on the web browser, we need to convert it into TensorFlow.js so that it becomes compatible to be run directly on the browser\n",
        "\n",
        "Also, the model only detects objects as the IDs specified in the `label_map.pbtxt`. Therefore, we also need to create a JSON list of all of our labels that can be mapped to the ID."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-f5lfcnp01e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b8028a-f2d5-41ed-8d70-cde9e4c2ddfb"
      },
      "source": [
        "!tensorflowjs_converter \\\n",
        "  --input_format=tf_frozen_model \\\n",
        "  --output_format=tfjs_graph_model \\\n",
        "  --output_node_names='Postprocessor/ExpandDims_1,Postprocessor/Slice' \\\n",
        "  --quantization_bytes=1 \\\n",
        "  --skip_op_check \\\n",
        "  $EXPORTED_PATH/frozen_inference_graph.pb \\\n",
        "  /content/model_web\n",
        "\n",
        "import json\n",
        "\n",
        "from object_detection.utils.label_map_util import get_label_map_dict\n",
        "\n",
        "label_map = get_label_map_dict(LABEL_MAP_PATH)\n",
        "label_array = [k for k in sorted(label_map, key=label_map.get)]\n",
        "\n",
        "with open(os.path.join('/content/model_web', 'labels.json'), 'w') as f:\n",
        "  json.dump(label_array, f)\n",
        "\n",
        "!cd /content/model_web && zip -r /content/model_web.zip *"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-09 10:43:13.497578: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\n",
            "2021-02-09 10:43:13.497639: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   debug_stripper: Graph size after: 3349 nodes (0), 4168 edges (0), time = 2.657ms.\n",
            "2021-02-09 10:43:13.497657: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   model_pruner: Graph size after: 2100 nodes (-1249), 2355 edges (-1813), time = 15.046ms.\n",
            "2021-02-09 10:43:13.497676: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 625 nodes (-1475), 687 edges (-1668), time = 222.63ms.\n",
            "2021-02-09 10:43:13.497692: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   arithmetic_optimizer: Graph size after: 475 nodes (-150), 646 edges (-41), time = 37.495ms.\n",
            "2021-02-09 10:43:13.497707: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   dependency_optimizer: Graph size after: 469 nodes (-6), 639 edges (-7), time = 9.504ms.\n",
            "2021-02-09 10:43:13.497721: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   model_pruner: Graph size after: 469 nodes (0), 639 edges (0), time = 14.247ms.\n",
            "2021-02-09 10:43:13.497735: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 469 nodes (0), 639 edges (0), time = 79.642ms.\n",
            "2021-02-09 10:43:13.497750: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   arithmetic_optimizer: Graph size after: 467 nodes (-2), 635 edges (-4), time = 35.011ms.\n",
            "2021-02-09 10:43:13.497771: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   dependency_optimizer: Graph size after: 467 nodes (0), 635 edges (0), time = 10.038ms.\n",
            "2021-02-09 10:43:13.497785: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   debug_stripper: debug_stripper did nothing. time = 0.473ms.\n",
            "2021-02-09 10:43:13.497800: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   model_pruner: Graph size after: 467 nodes (0), 635 edges (0), time = 13.019ms.\n",
            "2021-02-09 10:43:13.497814: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 467 nodes (0), 635 edges (0), time = 42.297ms.\n",
            "2021-02-09 10:43:13.497828: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   arithmetic_optimizer: Graph size after: 467 nodes (0), 635 edges (0), time = 36.671ms.\n",
            "2021-02-09 10:43:13.497843: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   dependency_optimizer: Graph size after: 467 nodes (0), 635 edges (0), time = 9.501ms.\n",
            "2021-02-09 10:43:13.497857: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   model_pruner: Graph size after: 467 nodes (0), 635 edges (0), time = 14.449ms.\n",
            "2021-02-09 10:43:13.497872: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 467 nodes (0), 635 edges (0), time = 45.562ms.\n",
            "2021-02-09 10:43:13.497886: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   arithmetic_optimizer: Graph size after: 467 nodes (0), 635 edges (0), time = 37.012ms.\n",
            "2021-02-09 10:43:13.497900: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   dependency_optimizer: Graph size after: 467 nodes (0), 635 edges (0), time = 9.817ms.\n",
            "2021-02-09 10:43:14.267941: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\n",
            "2021-02-09 10:43:14.268002: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   remapper: Graph size after: 455 nodes (-12), 623 edges (-12), time = 15.87ms.\n",
            "2021-02-09 10:43:14.268013: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 455 nodes (0), 623 edges (0), time = 51.243ms.\n",
            "2021-02-09 10:43:14.268021: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   arithmetic_optimizer: Graph size after: 455 nodes (0), 623 edges (0), time = 34.223ms.\n",
            "2021-02-09 10:43:14.268034: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   dependency_optimizer: Graph size after: 455 nodes (0), 623 edges (0), time = 9.305ms.\n",
            "2021-02-09 10:43:14.268043: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   remapper: Graph size after: 455 nodes (0), 623 edges (0), time = 13.314ms.\n",
            "2021-02-09 10:43:14.268054: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 455 nodes (0), 623 edges (0), time = 41.524ms.\n",
            "2021-02-09 10:43:14.268074: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   arithmetic_optimizer: Graph size after: 455 nodes (0), 623 edges (0), time = 34.558ms.\n",
            "2021-02-09 10:43:14.268086: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   dependency_optimizer: Graph size after: 455 nodes (0), 623 edges (0), time = 9.1ms.\n",
            "Writing weight file /content/model_web/model.json...\n",
            "  adding: group1-shard1of2.bin (deflated 23%)\n",
            "  adding: group1-shard2of2.bin (deflated 25%)\n",
            "  adding: labels.json (deflated 17%)\n",
            "  adding: model.json (deflated 93%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1iFI9pPr1l7"
      },
      "source": [
        "#### **Download the model**\n",
        "The TFJS model is now ready to be downloaded.\n",
        "\n",
        "> **Note:** Sometimes this command doesn't run or it will throw an error. Just try running it again.\n",
        "\n",
        "You can also download the model by right clicking on the `model_web.zip` file in the left sidebar file inspector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL_miSj2r1yt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f1cd1d4f-933a-438b-c2e3-ceda85b73ed9"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/model_web.zip') "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c6d30aad-19ee-4f8f-b8ef-257370ae1d80\", \"model_web.zip\", 4267213)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3WHwIZ0QlVP"
      },
      "source": [
        "# Next steps / Using the model\n",
        "Use the `model_web` folder generated here, with React Web App created in the repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FuJZtnRbo7E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}